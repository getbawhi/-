{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eb35c9",
   "metadata": {},
   "source": [
    "# 사이킷런을 이용한 특징 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93ae8d",
   "metadata": {},
   "source": [
    "* 자연어 처리에서 특징 추출이란 ? </br>\n",
    "    - 텍스트 데이터에서 단어나 문장을 특정 값으로 바꿔주는 것을 말함 \n",
    "    - 문자 에서 >> 특징 뽑기 >> 수치화\n",
    " </br>   \n",
    "</br>\n",
    "\n",
    "* 텍스트 수치화 방법 3 가지 \n",
    "    </br>\n",
    "    - CountVectorizer :  단순히 각 텍스트의 횟수를 기준으로 특징 추출\n",
    "    </br>\n",
    "    - TfidfVectorizer :  TF-IDF라는 값을 사용\n",
    "    </br>\n",
    "    - HashingVectorizer :  Count 방식과 동일한 방법을 쓰지만, 해시함수를 사용해 시간을 줄일 수 있다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0441a93",
   "metadata": {},
   "source": [
    "## CountVectorizer \n",
    "\n",
    "* 어떤 단위의 횟수를 셀 것인지는 선택 사항 (단어 , 문자 하나하나 등) / 보통은 단어를 기준으로 횟수 측정 \n",
    "    - 문장을 입력으로 받아 단어의 횟수를 측정한 뒤 벡터로 만든다.\n",
    "    \n",
    "</br>\n",
    "\n",
    "* 진행과정\n",
    "\n",
    "    - 먼저 객체를 만들어야 한다\n",
    "    - 이 객체에 특정 텍스트를 적합시켜야 한다 (적합 : 횟수를 셀 단어의 목록을 만드는 과정)\n",
    "    - 횟수를 기준으로 해당 텍스트를 벡터화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fbe9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 텍스트를 불러온다. 여기서는 특정 데이터를 사용하지 않고 리스트로 텍스트 데이터를 직접 정의해서 사용한다.\n",
    "\n",
    "text_data =['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "count_vectorizer.fit(text_data) # fit 함수를 사용하면 자동으로 단어 사전을 생성함 \n",
    "\n",
    "# print(count_vectorizer.vocabulary_)\n",
    "\n",
    "# 이제 텍스트 데이터를 실제로 벡터로 만들어보자 / 정의한 텍스트 데이터 중에서 하나만 선택해 벡터로 만든다.\n",
    "\n",
    "sentence = [text_data[0]] # ['나는 배가 고프다']\n",
    "print(count_vectorizer.transform(sentence).toarray())\n",
    "\n",
    "#  [[1 0 1 0 0 0 1 0 0 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f621369",
   "metadata": {},
   "source": [
    "* 이처럼 매우 간단하게 텍스트 데이터에서 특징을 추출할 수 있다.\n",
    "</br></br>\n",
    "* 하지만 단순히 횟수만을 특징으로 잡기 때문에 큰 의미는 없지만 자주 사용되는 단어들 (조사, 지시대명사)가 </br>\n",
    "  높은 값을 가지기 때문에 유의미하게 사용하기 어려울 수 있다. \n",
    "  </br></br>\n",
    "* 이러한 점을 해결 해 줄 수 있는 TF-IDF 방식의 특징 추출을 알아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646137a3",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "\n",
    "* TF- IDF\n",
    "    - TF (Term Frequency) : 특정 단어가 하나의 데이터 안에서 등장하는 횟수를 의미 \n",
    "    - DF (Document Frequency) : 문서의 빈도 값, 특정 단어가 여러 데이터에 자주 등장하는지를 알려주는 지표다\n",
    "    - TF-IDF : 이 두 값을 곱해서 사용한다 \n",
    "    - 즉, 어떤 단어가 해당 문서에 자주 등장하지만 다른 문서에는 많이 없는 단어일수록 높은 값을 가지게 된다.\n",
    "    - 따라서 지시대명사, 조사 처럼 자주 등장하는 단어는 tf 값은 크지만 IDF 값은 작음 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3164ea53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
      "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "## 단어 사전 만들기\n",
    "\n",
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "sentence = [text_data[3]] # ['점심 먹고 공부 해야지']\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())\n",
    "\n",
    "# {'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
    "\n",
    "# [[0.         0.43779123 0.         0.         0.55528266 0.\n",
    "#   0.         0.43779123 0.         0.55528266]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624bc02",
   "metadata": {},
   "source": [
    "* 이 처럼 특징 추출 방법으로 TF-IDF 값을 사용할 경우 단순 횟수를 이용하는 것보다 각 단어의 특성을 더 잘 반영할 수 있음\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
